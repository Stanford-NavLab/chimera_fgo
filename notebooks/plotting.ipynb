{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from chimera_fgo.util.kitti import process_kitti_gt, load_icp_results\n",
    "from chimera_fgo.util.plot import plot_trajectories\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_seq = '0034'\n",
    "MAX_BIAS = 1\n",
    "start_idx = 1550 if kitti_seq == '0028' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth\n",
    "gtpath = os.path.join(os.getcwd(), '..', 'data', 'kitti', kitti_seq, 'oxts', 'data')\n",
    "gt_enu, gt_Rs, gt_attitudes = process_kitti_gt(gtpath, start_idx=start_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot spoofed trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJLEN = 1900\n",
    "gps_spoofing_biases = np.zeros(TRAJLEN)  \n",
    "attack_start_idx = 1000\n",
    "gps_spoofing_biases[attack_start_idx:] = MAX_BIAS * np.linspace(0, 1, TRAJLEN-attack_start_idx)  # Ramping attack\n",
    "\n",
    "spoof_pos_1 = gt_enu[:TRAJLEN].copy()\n",
    "spoof_pos_1[:,0] += 50 * gps_spoofing_biases\n",
    "spoof_pos_2 = gt_enu[:TRAJLEN].copy()\n",
    "spoof_pos_2[:,0] += 100 * gps_spoofing_biases\n",
    "spoof_pos_3 = gt_enu[:TRAJLEN].copy()\n",
    "spoof_pos_3[:,0] += 200 * gps_spoofing_biases\n",
    "\n",
    "gt_traj = go.Scatter(x=gt_enu[:TRAJLEN,0], y=gt_enu[:TRAJLEN,1], hovertext=np.arange(TRAJLEN), name='Ground-truth', line=dict(color='black'))\n",
    "spoof_traj_1 = go.Scatter(x=spoof_pos_1[:,0], y=spoof_pos_1[:,1], hovertext=np.arange(TRAJLEN), name='0.5 m/s spoofed', line=dict(color='red', dash='dot'))\n",
    "spoof_traj_2 = go.Scatter(x=spoof_pos_2[:,0], y=spoof_pos_2[:,1], hovertext=np.arange(TRAJLEN), name='1.0 m/s spoofed', line=dict(color='red', dash='dashdot'))\n",
    "spoof_traj_3 = go.Scatter(x=spoof_pos_3[:,0], y=spoof_pos_3[:,1], hovertext=np.arange(TRAJLEN), name='2.0 m/s spoofed', line=dict(color='red', dash='dash'))\n",
    "\n",
    "start = go.Scatter(x=[0], y=[0], name='Start', mode='markers', marker=dict(size=10, color='black'), showlegend=False)\n",
    "spoof_start = go.Scatter(x=[gt_enu[attack_start_idx,0]], y=[gt_enu[attack_start_idx,1]], \n",
    "            name='Spoofing start', mode='markers', marker=dict(size=10, color='red'), showlegend=True)\n",
    "fig = go.Figure(data=[gt_traj, spoof_traj_1, spoof_traj_2, spoof_traj_3, start, spoof_start])\n",
    "fig.update_layout(width=1000, height=1000, xaxis_title='East [m]', yaxis_title='North [m]')\n",
    "# Move legend into plot\n",
    "fig.update_layout(legend=dict(x=0.05, y=0.98), font=dict(size=18))\n",
    "fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    "  )\n",
    "#fig.update_xaxes(autorange=True)\n",
    "fig.update_xaxes(range=[-50, 950])\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Lidar odometry, blind FGO, and FGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lidar odometry\n",
    "data_path = os.path.join(os.getcwd(), '..', 'data', 'kitti', kitti_seq, 'icp')\n",
    "lidar_Rs, lidar_ts, lidar_positions, lidar_covariances = load_icp_results(data_path, start_idx=start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "run_name = 'fgo_100m_5runs_2023-01-19-0507'\n",
    "results_path = os.path.join(os.getcwd(), '..', 'results', kitti_seq, run_name)\n",
    "results_files = os.listdir(results_path)\n",
    "fgo_results = np.load(os.path.join(results_path, results_files[0]))\n",
    "fgo_positions = fgo_results['positions']\n",
    "\n",
    "run_name = 'fgo_100m_5runs_blind_2023-01-19-0528'\n",
    "results_path = os.path.join(os.getcwd(), '..', 'results', kitti_seq, run_name)\n",
    "results_files = os.listdir(results_path)\n",
    "fgo_blind_results = np.load(os.path.join(results_path, results_files[0]))\n",
    "fgo_blind_positions = fgo_blind_results['positions']\n",
    "\n",
    "spoofed_positions = fgo_results['spoofed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "ATTACK_START = 1000\n",
    "N = 1900\n",
    "fgo_traj = go.Scatter(x=fgo_positions[:,0], y=fgo_positions[:,1], name='FGO', line=dict(color='blue'))\n",
    "fgo_blind_traj = go.Scatter(x=fgo_blind_positions[:,0], y=fgo_blind_positions[:,1], name='FGO blind', line=dict(color='orange'))\n",
    "gt_traj = go.Scatter(x=gt_enu[:N,0], y=gt_enu[:N,1], name='Ground-truth', line=dict(color='black'))\n",
    "lidar_traj = go.Scatter(x=lidar_positions[:N,0], y=lidar_positions[:N,1], name='Lidar odometry', line=dict(color='green'))\n",
    "start = go.Scatter(x=[0], y=[0], name='Start', mode='markers', marker=dict(size=10, color='blue'), showlegend=False)\n",
    "plot_data = [fgo_traj, fgo_blind_traj, lidar_traj, gt_traj, start]\n",
    "\n",
    "spoof_traj = go.Scatter(x=spoofed_positions[:,0], y=spoofed_positions[:,1], \n",
    "    name='Spoofed', line=dict(color='red', dash='dash')) \n",
    "spoof_start = go.Scatter(x=[spoofed_positions[ATTACK_START,0]], y=[spoofed_positions[ATTACK_START,1]], \n",
    "    name='Spoofing start', mode='markers', marker=dict(size=10, color='red'), showlegend=False)\n",
    "plot_data += [spoof_traj, spoof_start]\n",
    "\n",
    "\n",
    "# detect = go.Scatter(x=[graph_positions[detect_idx,0]], y=[graph_positions[detect_idx,1]], \n",
    "#     name='Detection', mode='markers', hovertext=str(detect_idx), marker=dict(size=10, color='green'), showlegend=True)\n",
    "# plot_data += [detect]\n",
    "\n",
    "fig = go.Figure(data=plot_data)\n",
    "fig.update_layout(width=1000, height=1000, xaxis_title='East [m]', yaxis_title='North [m]')\n",
    "# Move legend into plot\n",
    "fig.update_layout(legend=dict(x=0.02, y=0.98), font=dict(size=18))\n",
    "fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    "  )\n",
    "fig.update_xaxes(autorange=True)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_seq = '0018'\n",
    "run_name = 'fgo_0m_100runs_blind_2023-01-19-2054'\n",
    "results_path = os.path.join(os.getcwd(), '..', 'results', kitti_seq, run_name)\n",
    "results_files = os.listdir(results_path)\n",
    "fgo_blind_results = np.load(os.path.join(results_path, results_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qs_plot = fgo_results['qs']\n",
    "qs_plot = fgo_blind_results['qs']\n",
    "T = fgo_results['threshold']\n",
    "GPS_RATE = 10\n",
    "detect_idx = np.argmax(qs_plot > T)\n",
    "\n",
    "# Plot test statistic and threshold\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(qs_plot)), y=qs_plot, name='Test statistic'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(qs_plot)), y=T*np.ones(len(qs_plot)), name='Threshold', line=dict(color='black', dash='dash')))\n",
    "# Add vertical line at start of spoofing attack\n",
    "fig.add_trace(go.Scatter(x=[100, 100], y=[min(qs_plot), max(qs_plot)], mode='lines', name='Start of attack', line=dict(color='red', dash='dash')))\n",
    "# fig.add_shape(type=\"line\", x0=ATTACK_START/GPS_RATE, y0=-20, x1=ATTACK_START/GPS_RATE, y1=200, name='Start of attack', \n",
    "#               line=dict(color=\"red\", width=2, dash=\"dash\"), showlegend=True)\n",
    "fig.add_trace(go.Scatter(x=[detect_idx], y=[qs_plot[detect_idx]], name='Detection', mode='markers', marker=dict(size=10, color='red'), showlegend=True))\n",
    "fig.update_layout(width=900, height=500, xaxis_title='Time [s]', yaxis_title='Test statistic')\n",
    "fig.update_layout(legend=dict(x=0.05, y=0.98), font=dict(size=18))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = len(results_files)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "per_trial_FA = 0\n",
    "per_run_FA = 0\n",
    "\n",
    "for i in range(n_runs):\n",
    "    results = np.load(os.path.join(results_path, results_files[i]))\n",
    "    qs = results['qs']\n",
    "    T = results['threshold']\n",
    "    detect_idx = np.argmax(qs > T)\n",
    "    showlegend = True if i == 0 else False\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(qs)), y=qs, name='Test statistic', line=dict(color='blue'), showlegend=showlegend))\n",
    "    #fig.add_trace(go.Scatter(x=[detect_idx], y=[qs[detect_idx]], name='Detection', mode='markers', marker=dict(size=10, color='red'), showlegend=showlegend))\n",
    "    per_trial_FA += sum(qs > T)\n",
    "    per_run_FA += 1 if sum(qs > T) > 0 else 0\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(qs)), y=T*np.ones(len(qs)), name='Threshold', line=dict(color='black', dash='dash')))\n",
    "#fig.add_trace(go.Scatter(x=[100, 100], y=[50, 400], mode='lines', name='Start of attack', line=dict(color='red', dash='dash')))\n",
    "fig.update_layout(width=900, height=500, xaxis_title='Time [s]', yaxis_title='Test statistic')\n",
    "fig.update_layout(legend=dict(x=0.05, y=0.98), font=dict(size=18))\n",
    "fig.update_yaxes(range=[50, 200])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_trial_FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_run_FA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot error over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_seq = '0027'\n",
    "fgo_run = 'fgo_-200m_20runs_100w_2023-01-20-2106'\n",
    "fgo_blind_run = 'fgo_-200m_20runs_blind_2023-01-20-2223'\n",
    "N = 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "colors = px.colors.qualitative.D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgo_results_path = os.path.join(os.getcwd(), '..', 'results', kitti_seq, fgo_run)\n",
    "fgo_results_files = os.listdir(fgo_results_path)\n",
    "\n",
    "fgo_blind_results_path = os.path.join(os.getcwd(), '..', 'results', kitti_seq, fgo_blind_run)\n",
    "fgo_blind_results_files = os.listdir(fgo_blind_results_path)\n",
    "\n",
    "start_idx = 1550 if kitti_seq == '0028' else 0\n",
    "gtpath = os.path.join(os.getcwd(), '..', 'data', 'kitti', kitti_seq, 'oxts', 'data')\n",
    "gt_enu, gt_Rs, gt_attitudes = process_kitti_gt(gtpath, start_idx=start_idx)\n",
    "data_path = os.path.join(os.getcwd(), '..', 'data', 'kitti', kitti_seq, 'icp')\n",
    "lidar_Rs, lidar_ts, lidar_positions, lidar_covariances = load_icp_results(data_path, start_idx=start_idx)\n",
    "\n",
    "n_runs = len(fgo_blind_results_files)\n",
    "fgo_blind_err_avg = np.zeros(1900)\n",
    "fgo_err_avg = np.zeros(1900)\n",
    "time = np.arange(1900) / 10\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[100, 100], y=[0, 300], mode='lines', name='Start of attack', line=dict(color='red', dash='dash'), showlegend=False))\n",
    "\n",
    "for i in range(n_runs):\n",
    "    fgo_results = np.load(os.path.join(fgo_results_path, fgo_results_files[i]))\n",
    "    fgo_blind_results = np.load(os.path.join(fgo_blind_results_path, fgo_blind_results_files[i]))\n",
    "    fgo_positions = fgo_results['positions']\n",
    "    fgo_blind_positions = fgo_blind_results['positions']\n",
    "    \n",
    "    fgo_blind_err = np.linalg.norm(fgo_blind_positions - gt_enu[:N], axis=1)\n",
    "    fgo_err = np.linalg.norm(fgo_positions - gt_enu[:N], axis=1)\n",
    "    # fgo_blind_err_avg += fgo_blind_err\n",
    "    # fgo_err_avg += fgo_err\n",
    "    showlegend = True if i == 0 else False\n",
    "    fig.add_trace(go.Scatter(x=time, y=fgo_blind_err, name='Naive FGO', line=dict(color='orange'), showlegend=showlegend))\n",
    "    fig.add_trace(go.Scatter(x=time, y=fgo_err, name='SR FGO', line=dict(color='blue'), showlegend=showlegend))\n",
    "\n",
    "\n",
    "lidar_err = np.linalg.norm(lidar_positions[:N] - gt_enu[:N], axis=1)\n",
    "fgo_blind_err_avg /= n_runs\n",
    "fgo_err_avg /= n_runs\n",
    "\n",
    "fig.add_trace(go.Scatter(x=time, y=lidar_err, name='Odometry only', line=dict(color='green')))\n",
    "# fig.add_trace(go.Scatter(x=np.arange(len(fgo_blind_err_avg)), y=fgo_blind_err_avg, name='FGO blind'))\n",
    "# fig.add_trace(go.Scatter(x=np.arange(len(fgo_err_avg)), y=fgo_err_avg, name='FGO'))\n",
    "fig.update_layout(width=900, height=500, xaxis_title='Time [s]', yaxis_title='L2 norm error [m]')\n",
    "fig.update_layout(legend=dict(x=0.05, y=0.98), font=dict(size=18))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized error scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1900\n",
    "lidar_mean_errs = []\n",
    "lidar_max_errs = []\n",
    "\n",
    "for kitti_seq in ['0018', '0027', '0028', '0034']:\n",
    "\n",
    "    start_idx = 1550 if kitti_seq == '0028' else 0\n",
    "    gtpath = os.path.join(os.getcwd(), '..', 'data', 'kitti', kitti_seq, 'oxts', 'data')\n",
    "    gt_enu, gt_Rs, gt_attitudes = process_kitti_gt(gtpath, start_idx=start_idx)\n",
    "    data_path = os.path.join(os.getcwd(), '..', 'data', 'kitti', kitti_seq, 'icp')\n",
    "    lidar_Rs, lidar_ts, lidar_positions, lidar_covariances = load_icp_results(data_path, start_idx=start_idx)\n",
    "\n",
    "    # Compute RMSE and max error for lidar for each sequence\n",
    "    lidar_err = np.linalg.norm(lidar_positions[:N] - gt_enu[:N], axis=1)\n",
    "    print(\"Mean error: \", np.mean(lidar_err))\n",
    "    print(\"Max error: \", np.max(lidar_err))\n",
    "    lidar_mean_errs.append(np.mean(lidar_err))\n",
    "    lidar_max_errs.append(np.max(lidar_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [['fgo_0m_10runs_2023-01-18-1754', 'fgo_50m_5runs_2023-01-19-0042', 'fgo_100m_5runs_2023-01-19-0121', 'fgo_200m_20runs_2023-01-19-2015'], # 0018\n",
    "        ['fgo_0m_10runs_2023-01-18-1843', 'fgo_50m_5runs_2023-01-19-0237', 'fgo_100m_5runs_2023-01-19-0313', 'fgo_200m_20runs_2023-01-19-2308'], # 0027\n",
    "        ['fgo_0m_10runs_2023-01-18-1920', 'fgo_50m_5runs_2023-01-19-0428', 'fgo_100m_5runs_2023-01-19-0507', 'fgo_200m_20runs_2023-01-20-0138'], # 0028\n",
    "        ['fgo_0m_10runs_2023-01-18-2000', 'fgo_50m_5runs_2023-01-19-0627', 'fgo_100m_5runs_2023-01-19-0707', 'fgo_200m_20runs_100w_2023-01-20-0846']] # 0034\n",
    "mean_errors = np.zeros((4, 4))\n",
    "max_errors = np.zeros((4, 4))\n",
    "mean_errors_std = np.zeros((4, 4))\n",
    "max_errors_std = np.zeros((4, 4))\n",
    "\n",
    "runs_blind = [['fgo_0m_100runs_blind_2023-01-19-2054', 'fgo_50m_5runs_blind_2023-01-19-0102', 'fgo_100m_20runs_blind_2023-01-20-1012', 'fgo_200m_20runs_blind_2023-01-19-2142'], # 0018\n",
    "        ['fgo_0m_100runs_blind_2023-01-18-2330', 'fgo_50m_5runs_blind_2023-01-19-0255', 'fgo_100m_20runs_blind_2023-01-20-1251', 'fgo_200m_20runs_blind_2023-01-20-0025'], # 0027\n",
    "        ['fgo_0m_100runs_blind_2023-01-18-2330', 'fgo_50m_5runs_blind_2023-01-19-0448', 'fgo_100m_20runs_blind_2023-01-20-1526', 'fgo_200m_20runs_blind_2023-01-20-0300'], # 0028\n",
    "        ['fgo_0m_100runs_blind_2023-01-18-2330', 'fgo_50m_5runs_blind_2023-01-19-0647', 'fgo_100m_20runs_blind_2023-01-20-1810', 'fgo_200m_20runs_blind_2023-01-20-1013']] # 0034\n",
    "mean_errors_blind = np.zeros((4, 4))\n",
    "max_errors_blind = np.zeros((4, 4))\n",
    "mean_errors_blind_std = np.zeros((4, 4))\n",
    "max_errors_blind_std = np.zeros((4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = ['0018', '0027', '0028', '0034']\n",
    "for i in range(4):\n",
    "    kitti_seq = traces[i]\n",
    "    start_idx = 1550 if kitti_seq == '0028' else 0\n",
    "    gtpath = os.path.join(os.getcwd(), '..', 'data', 'kitti', kitti_seq, 'oxts', 'data')\n",
    "    gt_enu, gt_Rs, gt_attitudes = process_kitti_gt(gtpath, start_idx=start_idx)\n",
    "    for j in range(4):\n",
    "        # SR FGO\n",
    "        run = runs[i][j]\n",
    "        fgo_results_path = os.path.join(os.getcwd(), '..', 'results', kitti_seq, run)\n",
    "        fgo_results_files = os.listdir(fgo_results_path)\n",
    "\n",
    "        mean_errs = []\n",
    "        max_errs = []\n",
    "        for k in range(5):\n",
    "            fgo_results = np.load(os.path.join(fgo_results_path, fgo_results_files[k]))\n",
    "            fgo_positions = fgo_results['positions']\n",
    "            err = np.linalg.norm(fgo_positions - gt_enu[:N], axis=1)\n",
    "            # print(\"Mean error: \", np.mean(err))\n",
    "            # print(\"Max error: \", np.max(err))\n",
    "            mean_errs.append(np.mean(err))\n",
    "            max_errs.append(np.max(err))\n",
    "        mean_errs_mean = np.mean(mean_errs)\n",
    "        mean_errs_std = np.std(mean_errs)\n",
    "        max_errs_mean = np.mean(max_errs)\n",
    "        max_errs_std = np.std(max_errs)\n",
    "        mean_errors[i,j] = mean_errs_mean #/ lidar_mean_errs[i]\n",
    "        max_errors[i,j] = max_errs_mean #/ lidar_max_errs[i]\n",
    "        mean_errors_std[i,j] = mean_errs_std\n",
    "        max_errors_std[i,j] = max_errs_std\n",
    "\n",
    "        # Naive FGO\n",
    "        run_blind = runs_blind[i][j]\n",
    "        fgo_results_path = os.path.join(os.getcwd(), '..', 'results', kitti_seq, run_blind)\n",
    "        fgo_results_files = os.listdir(fgo_results_path)\n",
    "\n",
    "        mean_errs = []\n",
    "        max_errs = []\n",
    "        for k in range(5):\n",
    "            fgo_results = np.load(os.path.join(fgo_results_path, fgo_results_files[k]))\n",
    "            fgo_positions = fgo_results['positions']\n",
    "            err = np.linalg.norm(fgo_positions - gt_enu[:N], axis=1)\n",
    "            # print(\"Mean error: \", np.mean(err))\n",
    "            # print(\"Max error: \", np.max(err))\n",
    "            mean_errs.append(np.mean(err))\n",
    "            max_errs.append(np.max(err))\n",
    "        mean_errs_mean = np.mean(mean_errs)\n",
    "        mean_errs_std = np.std(mean_errs)\n",
    "        max_errs_mean = np.mean(max_errs)\n",
    "        max_errs_std = np.std(max_errs)\n",
    "        mean_errors_blind[i,j] = mean_errs_mean #/ lidar_mean_errs[i]\n",
    "        max_errors_blind[i,j] = max_errs_mean #/ lidar_max_errs[i]\n",
    "        mean_errors_blind_std[i,j] = mean_errs_std\n",
    "        max_errors_blind_std[i,j] = max_errs_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean error plot\n",
    "seq_i = 2\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=['0 m/s', '0.5 m.s', '1.0 m/s', '2.0 m/s'], y=4*[lidar_mean_errs[seq_i]], name='Lidar', mode='lines', line=dict(color='green', width=2, dash='dash')))\n",
    "fig.add_trace(go.Scatter(x=['0 m/s', '0.5 m.s', '1.0 m/s', '2.0 m/s'], y=mean_errors[seq_i], error_y=dict(type='data', array=mean_errors_std[seq_i], visible=True), \n",
    "    name='SR FGO', mode='markers', marker=dict(color='blue', size=10, symbol='diamond')))\n",
    "fig.add_trace(go.Scatter(x=['0 m/s', '0.5 m.s', '1.0 m/s', '2.0 m/s'], y=mean_errors_blind[seq_i], error_y=dict(type='data', array=mean_errors_blind_std[seq_i], visible=True),\n",
    "    name='Naive FGO', mode='markers', marker=dict(color='red', size=10, symbol='square')))\n",
    "fig.update_layout(width=900, height=500, xaxis_title='Spoofing rate', yaxis_title='Mean error (m)')\n",
    "fig.update_layout(legend=dict(x=1.02, y=0.98), font=dict(size=18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max error plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=['0 m/s', '0.5 m.s', '1.0 m/s', '2.0 m/s'], y=4*[lidar_max_errs[seq_i]], name='Lidar', mode='lines', line=dict(color='green', width=2, dash='dash')))\n",
    "fig.add_trace(go.Scatter(x=['0 m/s', '0.5 m.s', '1.0 m/s', '2.0 m/s'], y=max_errors[seq_i], error_y=dict(type='data', array=max_errors_std[seq_i], visible=True), \n",
    "    name='SR FGO', mode='markers', marker=dict(color='blue', size=10, symbol='diamond')))\n",
    "fig.add_trace(go.Scatter(x=['0 m/s', '0.5 m.s', '1.0 m/s', '2.0 m/s'], y=max_errors_blind[seq_i], error_y=dict(type='data', array=max_errors_blind_std[seq_i], visible=True),\n",
    "    name='Naive FGO', mode='markers', marker=dict(color='red', size=10, symbol='square')))\n",
    "fig.update_layout(width=900, height=500, xaxis_title='Spoofing rate', yaxis_title='Max error (m)')\n",
    "fig.update_layout(legend=dict(x=1.02, y=0.98), font=dict(size=18))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window size comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_seq = '0027'\n",
    "start_idx = 0\n",
    "gtpath = os.path.join(os.getcwd(), '..', 'data', 'kitti', kitti_seq, 'oxts', 'data')\n",
    "gt_enu, gt_Rs, gt_attitudes = process_kitti_gt(gtpath, start_idx=start_idx)\n",
    "runs = ['fgo_100m_5runs_20w_2023-01-19-2312', \n",
    "        'fgo_100m_5runs_50w_2023-01-19-2314',\n",
    "        'fgo_100m_5runs_100w_2023-01-19-2321',\n",
    "        'fgo_100m_5runs_200w_2023-01-19-2340']\n",
    "\n",
    "mean_errs = []\n",
    "max_errs = []\n",
    "avg_iter_times = []\n",
    "\n",
    "for run in runs:\n",
    "    fgo_results_path = os.path.join(os.getcwd(), '..', 'results', kitti_seq, run)\n",
    "    fgo_results_files = os.listdir(fgo_results_path)\n",
    "    run_mean_errs = []\n",
    "    run_max_errs = []\n",
    "    run_avg_iter_times = []\n",
    "    for k in range(5):\n",
    "        fgo_results = np.load(os.path.join(fgo_results_path, fgo_results_files[k]))\n",
    "        fgo_positions = fgo_results['positions']\n",
    "        N = len(fgo_positions)\n",
    "        err = np.linalg.norm(fgo_positions - gt_enu[:N], axis=1)\n",
    "        run_mean_errs.append(np.mean(err))\n",
    "        run_max_errs.append(np.max(err))\n",
    "        run_avg_iter_times.append(fgo_results['avg_iter_time'])\n",
    "    mean_errs.append(np.mean(run_mean_errs))\n",
    "    max_errs.append(np.mean(run_max_errs))\n",
    "    avg_iter_times.append(np.mean(run_avg_iter_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Window sizes: \", [20, 50, 100, 200])\n",
    "print(\"Mean error: \", mean_errs)\n",
    "print(\"Max error: \", max_errs)\n",
    "print(\"Avg iter time: \", avg_iter_times)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte carlo trajectory plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_seq = '0028'\n",
    "run_name = 'fgo_100m_5runs_2023-01-19-0507'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = os.path.join(os.getcwd(), '..', 'results', kitti_seq, run_name)\n",
    "results_files = os.listdir(results_path)\n",
    "\n",
    "start_idx = 1550 if kitti_seq == '0028' else 0\n",
    "gtpath = os.path.join(os.getcwd(), '..', 'data', 'kitti', kitti_seq, 'oxts', 'data')\n",
    "gt_enu, gt_Rs, gt_attitudes = process_kitti_gt(gtpath, start_idx=start_idx)\n",
    "\n",
    "N_SHIFT = 10\n",
    "\n",
    "for fname in results_files:\n",
    "    results = np.load(os.path.join(results_path, fname))\n",
    "    graph_positions = results['positions']\n",
    "    gt_enu = gt_enu[:graph_positions.shape[0]]\n",
    "    if MAX_BIAS != 0:\n",
    "        spoofed_positions = results['spoofed']\n",
    "    else: \n",
    "        spoofed_positions = None\n",
    "\n",
    "    qs = results['qs']\n",
    "    threshold = results['threshold']\n",
    "    if any(qs > threshold):\n",
    "        detect_idx = N_SHIFT * np.argmax(qs > threshold)\n",
    "    else:\n",
    "        detect_idx = None\n",
    "\n",
    "    plot_trajectories(gt_enu, graph_positions, spoofed_positions, detect_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte carlo errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_errors(fig, gt_enu, graph_positions):\n",
    "    traj_len = len(gt_enu)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=np.arange(traj_len), y=graph_positions[:,0] - gt_enu[:,0], name='x error'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(traj_len), y=graph_positions[:,1] - gt_enu[:,1], name='y error'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(traj_len), y=graph_positions[:,2] - gt_enu[:,2], name='z error'), row=3, col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error envelope\n",
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.05)\n",
    "\n",
    "for fname in results_files:\n",
    "    results = np.load(os.path.join(results_path, fname))\n",
    "    graph_positions = results['positions']\n",
    "    gt_enu = gt_enu[:graph_positions.shape[0]]\n",
    "    plot_errors(fig, gt_enu, graph_positions)\n",
    "\n",
    "fig.update_layout(width=1200, height=700)\n",
    "fig.update_layout(font=dict(size=15))\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal\n",
    "\n",
    "false_alarms = 0\n",
    "total_trials = 0\n",
    "trajectory_false_alarms = 0\n",
    "\n",
    "ss_start = 0  # Start of steady state\n",
    "xyz_errors = []\n",
    "\n",
    "for fname in results_files:\n",
    "    results = np.load(os.path.join(results_path, fname))\n",
    "\n",
    "    graph_positions = results['positions']\n",
    "    gt_enu = gt_enu[:graph_positions.shape[0]]\n",
    "\n",
    "    xyz_errors.append(gt_enu[ss_start:] - graph_positions[ss_start:])\n",
    "\n",
    "    # False alarm\n",
    "    qs = results['qs']\n",
    "    threshold = results['threshold']\n",
    "    false_alarms += np.sum(qs > threshold)\n",
    "    total_trials += len(qs)\n",
    "    if any(qs > threshold):\n",
    "        trajectory_false_alarms += 1\n",
    "\n",
    "\n",
    "print(f'Per trial false alarm rate: {false_alarms} of {total_trials}')\n",
    "print(f'Per trajectory false alarm rate: {trajectory_false_alarms} of {len(results_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_errors = np.vstack(xyz_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean: \", np.mean(xyz_errors, axis=0))\n",
    "print(\"std: \", np.std(xyz_errors, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chimera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5edd088d6b144d42777d3bfeb942dbfa3bc6a1fda937eadc36b79f380c5a6b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
